# 啃瓜笔记 
## Task01：概览西瓜书+南瓜书第1、2章（3天）
- [第1章：https://www.bilibili.com/video/BV1Mh411e7VU?p=2](https://www.bilibili.com/video/BV1Mh411e7VU?p=2)
- 第2章：视频教程正在赶制中，先自行看书学习，第2章严格来说是在学完具体机器学习算法（第3章及其以后章节的内容）后再来学的，因此本章能看懂多少就看多少，只需看到2.3.2即可，【2.3.3-ROC与AUC】及其以后的暂时都可以跳过，等学完后面的算法再回来认真研读。

## 相关概念
- 数据集、训练、测试
- 样本
- 特征、特征值
- 特征向量
- 标记空间、输出空间
- 假设空间
- 归纳偏好：任何一个有效的机器学习算法必有其偏好，当一种现象可以有多种理论来解释时，选择最简单的。
- NFL定理

## 模型评估与选择
1. 误差：学习器的预测输出与样本的真实输出之间的差异称为误差；在训练集上的误差通常称为经验误差，在新样本上的误差称为泛化误差。
- 拟合： 通过数据训练找到所有潜在样本的的“普遍规律”就是一种拟合过程。学习过程中，将样本一些特点或噪音当成了一般特质，就称为“过拟合”，“欠拟合”则相反，对样本的一般性质尚未学好。
2. 评估方法：通过实验测试来对学习器的泛化误差进行评估进而后做出选择。因此需要一个测试集来测试学习器对新样本的判别能力。测试集尽可能要与训练集互斥。几种常见的数据集拆分方法如下：
- 留出法：一般采用若干次随机按比例划分数据集为训练集和测试集，重复进行实验评估后取平均值做为留出法的评估结果。
- 交叉验证法：将数据集划分为K个大小相似的互斥子集，每次取k-1个子集的并集作为训练集，余下那个座位测试集，如此进行k次训练和测试。
- 自助法：对包含有m个样本的数据集D进行有放回的随机抽样，如此抽到的m个数据做为训练集，数据D剩余未被抽中的数据作为测试集。m次抽样中，数据未被抽中的概率=(1-1/m)^m,当m趋于无穷时，概率趋于0.368。
- 测试集的占比通常有1/10,1/3,1/5
- 调参与最终模型：模型学习过程都有些参数需要设定，参数配置不同，性能往往有显著差别。在进行模型评估与选择时，除了要对算法进行选择，还需对算法参数进行设定，这就是通常所说的’调参‘。通常用测试集上的判别效果来评估模型在实际使用时的泛化能力，而把训练集数据另外划分为训练集和验证集，基于验证集上的性能进行模型选择和调参。
3. 性能度量
- 度量模型泛化能力的评价准备，称为性能度量，不同性能度量选择取决于任务需求。如回归任务最常用的性能度量为均方误差。常见性能度量有：
- 错误率与精度
- 准确率与查全率：这里涉及到混淆矩阵相关概念，如真正例TP，假正例FP,假反例FN,真反例TN，则查准率p=TP/(TP+FP)，查准率R=TP/(TP+FN)
- F1度量：基于查准率和查全率的调和平均，1/F1=1/P+1/R
- F(beta): Fbeta = （1+（beta）^2）*P*R/((beta)^2*P + R)
- ROC 与 AUC
- 代价敏感错误率与代价曲线
4. 比较检验：（涉及概率论与数理统计中的t检验、F检验、X^2检验）
- 假设检验
- 交叉验证t检验
- McNemar检验
- Friedman检验和Nemenyi后续检验
- 偏差与方差

- 结语：
模型训练过程中涉及到样本集、检验相关概念数学基础，需要自行复习概率率与数理统计相关数学基础！

- 可以扫码关注公众号：Datawhale，参与啃瓜活动！
![Datawhale](https://datawhale-business.oss-cn-hangzhou.aliyuncs.com/87/dashboard/1730810362799/image.png)