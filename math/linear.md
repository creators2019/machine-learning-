# 线性代数 

## 1.矩阵及其基本运算
### 1.1.基本概念、意义、常见特殊矩阵
#### 基本概念
- 矩阵A(m,n)：是一个m行n列的数列, n=n时，称为方阵
- 行向量：m = 1行矩阵
- 列向量：n = 1 列矩阵
- 两个矩阵相等，行列相等，任意a(i,j)相等
- 零矩阵：a(ij) = 0
### 1.2.矩阵的加减数乘及性质
- 加减法运算： A + B = B + A ；(A + B) + C = A + (B+C)
- 数乘运算：abA = a(bA); (a+b)A = aA + bA; a(A+B)=aA+aB；注：小写字母代表实数，大写字母代表矩阵
### 1.3. 矩阵乘法及性质 A*B = C
-  两个矩阵相乘A(m,n) * B(n,s),，必须A的行与B的列相等
- C(ij) = a(i1)b(1j) + a(i2)b(2j) + ... + a(in)b(nj)
- 非特殊矩阵，不满足交换律 AB != BA
### 1.4. 矩阵运算在深度学习的应用
- 数字图片处理：输入一张数字0-9的图片，大小为10*10像素(单样本)，
- 将像素值拉成一个1*100的行向量X = (x1,x2,...x100)
- XW1 = Y(y1,y2,...,y512), W1是一个(100,512)的矩阵
- Yf(x) = Z(z1,z2,...,z512),f(x)是一个relu(x)分段函数，Y值做了一对一的变换
- ZW2 = Q(q1,q2,...,q10),W2是一个（512,10）矩阵
- Qg(x) = P(p1,p2,...p10),g(x)是一个softmax函数，对Q值做了一对一变换，输出概率值
- n个样本同理:
- 先将像素值拉成一个(n ,100)的矩阵
- W1变换：(n,100)*(100,512)得到(n,512)矩阵
- relu变换
- W2变换：(n,512) * (512,10)得到一个(n,10)的矩阵
- softmax变换：输出相应的概率
### 1.5. 矩阵迹、转置、对称矩阵（协方差矩阵）
1. 迹：n阶矩阵对角线(左上右下)上元素总和tr(A)称为迹
- tr(A) = a11+a22+...+ann
- tr(AB) = tr(BA)
2. 转置
- （AT）T = A
- (aA)T = aAT
- (A+B)T=AT+BT
- (AB)T = (BT)(AT)
3. 对称矩阵：
- 如果AT = A，则称A为对称矩阵
4. 协方差矩阵
- 例：N 个样本，每个样本的特征维度是n
- 协方差矩阵是对称矩阵：XTX 为样本的协方差矩阵
## 2.矩阵的行列式
### 行列式计算
- 矩阵A：
a b 
c d 
行列式|A|=ad-bc
矩阵可以表示为
a11 a12
a22 a22
- 引入逆序数概念，其中:
逆序数t(a11a22)=0,-1的0次方为1，则a11*a22前面符号为+，a11*a22=ad
逆序数t(a12a21)=1, -1的1次方为-1，则a12*a21号为-,a12*a21 = -bc
得到|A|=ad-bc
- 解方程组
a11x1+a12x2 = b1
a21x1+a22x2 = b2
矩阵形式：
a11 a12 b1
a21 a22 b2
D :
a11 a12
a21 a22
D1 :
a12 b1
a22 b2
D2:
a12 b1
a21 b2
则：
x1 = |D1|/|D|=(a12*b1-a22*b1)/a11*a22-a12*a21
x2 = |D2|/|D|=(a11*b2 - a21*b1)/a11*a22-a12*a21
- 三阶矩阵,n阶矩阵同理

## 3.矩阵逆
### 3.1逆计算、常用性质
- 矩阵A可逆，A'可逆，且(A')'=A
- (aA)'=A'/a
- (AT)' = (A')T
- (AB)'=B'A'
### 3.2矩阵逆运算在机器学习线性回归算法中的运用
- 预测房价购买能力案例
x1,x2,...xN是样本
y1,y2,....yN是标签
每个样本属性包含xi=[婚姻，存款，...,收入]等n个属性，则
x11*a1+x12*a2+...x1n*an=y1
x21*a1+x22*a2+...x2n*an=y2
....
xN1*a1+xN2*a2+...xNn*an=yN
X(N,n)*A = Y(N,1),X是N*n的样本矩阵，A是列向量，代表属性权重
则A=X'Y,X可逆且N=n的情况下成立
### 3.3分块举证
- 暂略

## 4.矩阵初等变换
- 设A是一个m*n矩阵
- 对A实施一次初等'行变换'，相当于A左乘一个m阶初等矩阵P，P(m,m)A;
- 对A实施一次'列变换'，相当于A右乘一个n*n阶矩阵Q，Q(n,n)
- A~B相当于存在P(m,m),Q(n,n),使得PAQ=B
### 4.1矩阵秩
- 可逆矩阵的秩等于矩阵的阶数，不可逆矩阵秩小于阶数
- 奇异矩阵的秩为0
#### 4.2秩在线性回归算法中的应用
- 例题：X(N,n)A(n,1) = Y(N,1) 通常n不等于N
- 求min||Xa-Y||^2 = J,对均方误差进行a求导
- dJ/da= 2(xa-y)x = 2xT(xa-y) = 0
- xTxa = xTy ,求是否存在(xTx)'，使得a = (xTx)'xTy
- 当N>n时，xTx是一个(n,n)矩阵，一般可逆，则 a = (xTx)'xTy
- 当N>n时，xTx(N,N)矩阵秩R(xTx)<=R(x),秩小于阶的矩阵不可逆
## 5. 矩阵特征值与特征向量
### 5.1向量的线性相关、无关与可逆矩阵的关系
- A为向量组a1,a2,...,am,如果存在k1*a1+k2*a2+...km*am = 0，则表明向量组A是线性相关的，否则无关
- A秩R=A阶，则线性无关，R<阶，线性相关
### 5.2向量内积、范数、正交、规范正交基
- 1. 内积：[x,y]=x1y1+x2y2+...+xnyn，称[x,y]为向量x与y的内积
- 内积是两个向量之间的运算，结果是一个实数,用矩阵记号表示:
- [x,y] = xTy, x,y都是n*1的列向量
- 内积运算和性质：
- [x,y] = [y,x]
- [入x,y]=入[x,y]
- [x+y,z]=[x,z]+[y,z]
- x!=0时，[x,x]>0 ,[x,x]=|x||x|cos90
- 应用于高维空间中两个样本之间的相似度的一种度量,如：
- cos(ab夹角)=[a,b]/|a||b|
- 2. 正交
- [x,y]=0,x与y正交
- n维向量a1...an两两正交,则a1...an线性无关
- 规范正交基：e1,e2,en单位向量,两两正交
- V中任意向量a可用e的线性表示:a=入1*e1 + 入2*e2+...入n*en
- 施密特正交化
### 5.3特征值和特征向量
- Ax = 入x，称入是矩阵A的特征向量,x是是A对应于特征值入的特征向量
- 如果n阶矩阵A 满足ATA=E，即AT=A'，则称A为正交矩阵
- 若方阵A的特征值是入
- 则 A^k 的特征值入^k
- A'的特征值是1/入，若A可逆
- 
## 矩阵对角化及二次型
### 对角化在数据压缩算法中的应用
### 正定性在机器学习线性回归算法中的运用
